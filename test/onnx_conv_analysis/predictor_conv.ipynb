{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def calculate_output_shape(cfg):\n",
    "    # const int output_h = (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;\n",
    "    # const int output_w = (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;\n",
    "    height, width = cfg['image_shape']\n",
    "    kernel_h, kernel_w = cfg['kernel_shape']\n",
    "    pad_h, pad_w = cfg['pads']\n",
    "    dilation_h, dilation_w = cfg['dilations']\n",
    "    stride_h, stride_w = cfg['strides']\n",
    "    output_h = (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) // stride_h + 1\n",
    "    output_w = (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) // stride_w + 1\n",
    "    output_shape = [cfg['batch_size'], cfg['output_channels'], output_h, output_w]\n",
    "    return output_shape\n",
    "\n",
    "\n",
    "def calculate_gmacs(item):\n",
    "    def reduce_list_prod(x):\n",
    "        return reduce(lambda a, b : a * b, x)\n",
    "    cfg = {\n",
    "        'image_shape' : [int(item['H']), int(item['W'])],\n",
    "        'kernel_shape' : [int(item['kH']), int(item['kW'])],\n",
    "        'pads' : [int(item['pad_h']), int(item['pad_w'])],\n",
    "        'dilations' : [int(item['dilation_h']), int(item['dilation_w'])],\n",
    "        'strides' : [int(item['stride_h']), int(item['stride_w'])],\n",
    "        'batch_size' : int(item['N']),\n",
    "        'output_channels' : int(item['kN']),\n",
    "    }\n",
    "    output_shape = calculate_output_shape(cfg)\n",
    "    gmacs = reduce_list_prod(output_shape) * reduce_list_prod(cfg['kernel_shape']) * int(item['C'])\n",
    "    return gmacs * 1e-9\n",
    "\n",
    "\n",
    "def data_processer(file_name : str, split : bool = False):\n",
    "    feature, energy, latency = [], [], []\n",
    "    with open(file_name, 'r') as fp:\n",
    "        f_csv = csv.DictReader(fp)\n",
    "        data = list(f_csv)\n",
    "    for item in data:\n",
    "        repeat = int(item['repeat'])\n",
    "        feature_vec = [\n",
    "                        # item['N'], \n",
    "                        # item['C'], \n",
    "                        # item['H'], \n",
    "                        item['W'], \n",
    "                        item['kN'], \n",
    "                        item['kC'], \n",
    "                        # item['kH'], \n",
    "                        item['kW'], \n",
    "                        # item['pad_h'], \n",
    "                        # item['pad_w'], \n",
    "                        # item['dilation_h'], \n",
    "                        # item['dilation_w'], \n",
    "                        item['stride_h'], \n",
    "                        # item['stride_w'], \n",
    "                        # item['group'], \n",
    "                        # item['has_bias'],\n",
    "                        calculate_gmacs(item),\n",
    "                    ]\n",
    "        feature_vec = [int(x) for x in feature_vec]\n",
    "        feature.append(feature_vec)\n",
    "        energy.append(float(item['energy']) / repeat)\n",
    "        latency.append(float(item['latency']) / repeat)\n",
    "    if split:\n",
    "        feature_train, feature_test, energy_train, energy_test, latency_train, latency_test, cfg_train, cfg_test = train_test_split(feature, energy, latency, data)\n",
    "        train_split = {\n",
    "            'feature' : feature_train,\n",
    "            'energy' : energy_train,\n",
    "            'latency' : latency_train,\n",
    "            'raw_cfg' : cfg_train,\n",
    "        }\n",
    "        test_split = {\n",
    "            'feature' : feature_test,\n",
    "            'energy' : energy_test,\n",
    "            'latency' : latency_test,\n",
    "            'raw_cfg' : cfg_test,\n",
    "        }\n",
    "        return train_split, test_split\n",
    "    else:\n",
    "        train_data = {\n",
    "            'feature' : feature,\n",
    "            'energy' : energy,\n",
    "            'latency' : latency,\n",
    "            'raw_cfg' : data,\n",
    "        }\n",
    "        return train_data\n",
    "train_data, val_data = data_processer('data/onnx_conv_resample_1w_results.csv', True)\n",
    "test_data = data_processer('data/onnx_conv_raw_results.csv', False)\n",
    "# pre-select test data\n",
    "valid_test_idx = [i for i in range(len(test_data['raw_cfg'])) if test_data['raw_cfg'][i]['group'] == '1']\n",
    "test_data = {\n",
    "    'feature' : [test_data['feature'][i] for i in valid_test_idx],\n",
    "    'energy' : [test_data['energy'][i] for i in valid_test_idx],\n",
    "    'latency' : [test_data['latency'][i] for i in valid_test_idx],\n",
    "    'raw_cfg' : [test_data['raw_cfg'][i] for i in valid_test_idx],\n",
    "}\n",
    "print(len(test_data['energy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_accuracy(y_pred, y_true, threshold = 0.01):\n",
    "    a = (y_true - y_pred) / y_true\n",
    "    b = np.where(abs(a) <= threshold)\n",
    "    return len(b[0]) / len(y_true)\n",
    "\n",
    "\n",
    "def get_metrics(y_pred, y_true):\n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) * 100\n",
    "    rmse = np.sqrt(mean_squared_error(y_pred, y_true))\n",
    "    error = rmse / np.mean(y_true)\n",
    "    acc5 = get_accuracy(y_pred, y_true, threshold=0.05)\n",
    "    acc10 = get_accuracy(y_pred, y_true, threshold=0.10)\n",
    "    acc15 = get_accuracy(y_pred, y_true, threshold=0.15)\n",
    "    print(f\"rmse: {rmse:.4f}; rmspe: {rmspe:.4f}; error: {error:.4f}; 5% accuracy: {acc5:.4f}; 10% accuracy: {acc10:.4f}; 15% accuracy: {acc15:.4f}.\")\n",
    "\n",
    "\n",
    "def large_error_indices(y_pred, y_true, threshold = 0.01):\n",
    "    a = (y_true - y_pred) / y_true\n",
    "    b = np.where(abs(a) > threshold)\n",
    "    return b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy Results:\n",
      "rmse: 0.2351; rmspe: 22.0409; error: 0.5490; 5% accuracy: 0.4512; 10% accuracy: 0.6928; 15% accuracy: 0.8244.\n",
      "\n",
      "Testing set:\n",
      "rmse: 0.0359; rmspe: 88.2635; error: 1.1389; 5% accuracy: 0.3715; 10% accuracy: 0.6231; 15% accuracy: 0.7908.\n",
      "\n",
      "latency Results:\n",
      "rmse: 0.0026; rmspe: 24.1217; error: 0.4612; 5% accuracy: 0.4732; 10% accuracy: 0.7252; 15% accuracy: 0.8440.\n",
      "\n",
      "Testing set:\n",
      "rmse: 0.0007; rmspe: 80.1667; error: 1.0822; 5% accuracy: 0.4869; 10% accuracy: 0.7397; 15% accuracy: 0.8497.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "n_features = len(train_data['feature'][0])\n",
    "\n",
    "large_error_items = []\n",
    "for label in [\"energy\", \"latency\"]:\n",
    "    model = RandomForestRegressor(\n",
    "        max_depth=50,\n",
    "        n_estimators=370,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        max_features=n_features,\n",
    "        oob_score=True,\n",
    "        random_state=10\n",
    "    )\n",
    "    model.fit(train_data[\"feature\"], train_data[label])\n",
    "    # val\n",
    "    predicts = model.predict(val_data[\"feature\"])\n",
    "    print(f'{label} Results:')\n",
    "    get_metrics(predicts, val_data[label])\n",
    "    print(\"\")\n",
    "    # test\n",
    "    predicts = model.predict(test_data[\"feature\"])\n",
    "    print('Testing set:')\n",
    "    get_metrics(predicts, test_data[label])\n",
    "    print(\"\")\n",
    "    # large error configs in train data\n",
    "    indices_train = large_error_indices(model.predict(train_data['feature']), train_data[label], 0.15)\n",
    "    items_train = [train_data['raw_cfg'][i] for i in indices_train]\n",
    "    large_error_items += items_train\n",
    "    # large error configs in val_data\n",
    "    indices_val = large_error_indices(model.predict(val_data['feature']), val_data[label], 0.15)\n",
    "    items_val = [val_data['raw_cfg'][i] for i in indices_val]\n",
    "    large_error_items += items_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total large error configs: 1257\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# save large error configs\n",
    "save_config = False\n",
    "print('total large error configs:', len(large_error_items))\n",
    "if save_config:\n",
    "    with open('data/large_error_items.csv', 'w') as f:\n",
    "        f_csv = csv.DictWriter(f, large_error_items[0].keys())\n",
    "        f_csv.writeheader()\n",
    "        f_csv.writerows(large_error_items)\n",
    "\n",
    "import sampling_conv as sc\n",
    "# resample configs\n",
    "nnmeter_format_configs = []\n",
    "for item in large_error_items:\n",
    "    c = {\n",
    "        'HW' : int(item['H']),\n",
    "        'CIN' : int(item['C']),\n",
    "        'COUT' : int(item['kN']),\n",
    "        'KERNEL_SIZE' : int(item['kH']),\n",
    "        'STRIDES' : int(item['stride_h']),\n",
    "    }\n",
    "    nnmeter_format_configs.append(c)\n",
    "ncfgs = sc.finegrained_sampling_conv(nnmeter_format_configs, 20)\n",
    "# save resampled configs\n",
    "fine_grained_configs = []\n",
    "for c in ncfgs:\n",
    "    conv_config = {\n",
    "        # flexible params\n",
    "        'image_shape' : [c['HW'], c['HW']],\n",
    "        'input_channels' : c['CIN'],\n",
    "        'kernel_channels' : c['CIN'],\n",
    "        'output_channels' : c['COUT'],\n",
    "        # constrained params\n",
    "        'batch_size' : 1,\n",
    "        'kernel_shape' : [c['KERNEL_SIZE'], c['KERNEL_SIZE']],\n",
    "        'pads' : [c['KERNEL_SIZE'] // 2, c['KERNEL_SIZE'] // 2],\n",
    "        'dilations' : [1, 1],\n",
    "        'strides' : [c['STRIDES'], c['STRIDES']],\n",
    "        'group' : 1,\n",
    "        'has_bias' : True,\n",
    "    }\n",
    "    fine_grained_configs.append(conv_config)\n",
    "\n",
    "if save_config:\n",
    "    with open('data/fine_grained_configs.json', 'w') as f:\n",
    "        json.dump(fine_grained_configs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy Results:\n",
      "rmse: 0.2447; rmspe: 10.3723; error: 0.5716; 5% accuracy: 0.5556; 10% accuracy: 0.8012; 15% accuracy: 0.9004.\n",
      "\n",
      "Testing set:\n",
      "rmse: 0.0472; rmspe: 100.0482; error: 1.4980; 5% accuracy: 0.4052; 10% accuracy: 0.6950; 15% accuracy: 0.8410.\n",
      "\n",
      "latency Results:\n",
      "rmse: 0.0023; rmspe: 10.1538; error: 0.4085; 5% accuracy: 0.5832; 10% accuracy: 0.8232; 15% accuracy: 0.9172.\n",
      "\n",
      "Testing set:\n",
      "rmse: 0.0010; rmspe: 102.0527; error: 1.4660; 5% accuracy: 0.5414; 10% accuracy: 0.8083; 15% accuracy: 0.9063.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fine_grained_data = data_processer('data/onnx_conv_fine_grained_1w_results.csv', False)\n",
    "# merge finegrained data into train data\n",
    "for key in train_data.keys():\n",
    "    train_data[key] += fine_grained_data[key]\n",
    "# build predictor again\n",
    "large_error_items = []\n",
    "large_error_test_items = {}\n",
    "for label in [\"energy\", \"latency\"]:\n",
    "    model = RandomForestRegressor(\n",
    "        max_depth=50,\n",
    "        n_estimators=370,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        max_features=n_features,\n",
    "        oob_score=True,\n",
    "        random_state=10\n",
    "    )\n",
    "    model.fit(train_data[\"feature\"], train_data[label])\n",
    "    # val\n",
    "    predicts = model.predict(val_data[\"feature\"])\n",
    "    print(f'{label} Results:')\n",
    "    get_metrics(predicts, val_data[label])\n",
    "    print(\"\")\n",
    "    # test\n",
    "    predicts = model.predict(test_data[\"feature\"])\n",
    "    print('Testing set:')\n",
    "    get_metrics(predicts, test_data[label])\n",
    "    # large error items in test data\n",
    "    indices_test = large_error_indices(model.predict(test_data['feature']), test_data[label], 0.15)\n",
    "    items_test = [test_data['raw_cfg'][i] for i in indices_test]\n",
    "    large_error_test_items[label] = items_test\n",
    "    print(\"\")\n",
    "    # large error configs in train data\n",
    "    indices_train = large_error_indices(model.predict(train_data['feature']), train_data[label], 0.15)\n",
    "    items_train = [train_data['raw_cfg'][i] for i in indices_train]\n",
    "    large_error_items += items_train\n",
    "    # large error configs in val_data\n",
    "    indices_val = large_error_indices(model.predict(val_data['feature']), val_data[label], 0.15)\n",
    "    items_val = [val_data['raw_cfg'][i] for i in indices_val]\n",
    "    large_error_items += items_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30774\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data['feature']))\n",
    "\n",
    "with open('data/failed_test_energy_items.csv', 'w') as f:\n",
    "        f_csv = csv.DictWriter(f, large_error_test_items['energy'][0].keys())\n",
    "        f_csv.writeheader()\n",
    "        f_csv.writerows(large_error_test_items['energy'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a15509c6e70554471c8dc63e93658ce4a46c97c632ba671a7bf04a0d21c57f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
